{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adondevivir.com Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be doing web scraping of apartment data from the website www.adondevivir.com using BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from urllib.request import urlopen as uReq\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "# Creating file\n",
    "filename = \"apartments.csv\"\n",
    "f= open(filename, \"w\")\n",
    "headers = \"Address,Price,Apartments,Bedrooms,Area,Bathrooms,Parking Slots,Status,Delivery,Services,Date Published,Link\\n\"\n",
    "f.write(headers)\n",
    "\n",
    "# Searching for apartments\n",
    "num_of_pages = 5\n",
    "for page in range(1, num_of_pages):\n",
    "    print(\"Page number \", page)\n",
    "    browser = webdriver.Chrome(\"C:\\chromedriver.exe\")\n",
    "    if (page == 1):\n",
    "        page_search = \"https://www.adondevivir.com/departamentos-en-venta-en-santiago-de-surco-a-estrenar.html\"\n",
    "    else:\n",
    "        page_search = \"https://www.adondevivir.com/departamentos-en-venta-en-santiago-de-surco-a-estrenar-pagina-\" + str(page) + \".html\"\n",
    "    \n",
    "    browser.get(page_search)\n",
    "    page_html = browser.page_source\n",
    "    page_soup = soup(page_html, \"html.parser\")\n",
    "    page_results = page_soup.findAll(\"div\", {\"class\":\"postingCardInfo\"})\n",
    "\n",
    "    # Reading every page result \n",
    "    for result in page_results:\n",
    "        \n",
    "        # Getting address of building\n",
    "        address_span = result.findAll(\"span\", {\"class\":\"postingCardLocationTitle\"})\n",
    "        address = address_span[0].text.strip('\\n\\r\\tS/\": ')\n",
    "\n",
    "        # Getting Number of Apartments, Area, Bedrooms, Bathrooms, Parking Slots for the building\n",
    "        data = result.findAll(\"li\")\n",
    "\n",
    "        apartments = 'None'\n",
    "        bedrooms = 'None'\n",
    "        area = 'None'\n",
    "        bathrooms = \"None\"\n",
    "        parking_slots = \"None\"\n",
    "\n",
    "        for i in range(len(data)):\n",
    "            line = data[i].findAll(\"i\")\n",
    "            if \"iconUnits\" in line[0]['class']:\n",
    "                apartments = data[i].text.strip('tuni.\\n\\r\\t\": ')\n",
    "            elif \"iconBedrooms\" in line[0]['class']:\n",
    "                bedrooms = data[i].text.strip('dorm.\\n\\r\\t\": ')\n",
    "            elif \"iconArea\" in line[0]['class']:\n",
    "                area = data[i].text.strip('m².\\n\\r\\t\": ')\n",
    "            elif \"iconBathroom\" in line[0]['class']:\n",
    "                bathrooms = data[i].text\n",
    "            elif \"iconGarage\" in line[0]['class']:\n",
    "                parking_slots = data[i].text.replace(\"estac.\", \"\").strip()\n",
    "\n",
    "        # Go to link to get more detailed information about the building and each apartment in the building\n",
    "        link_list = result.findAll(\"a\", {\"class\":\"go-to-posting\"})\n",
    "        new_link = \"https://www.adondevivir.com\" + linkList[0]['href'] \n",
    "        browser = webdriver.Chrome(\"C:\\chromedriver.exe\")\n",
    "        browser.get(new_link)\n",
    "        time.sleep(1)\n",
    "        page_html_new = browser.page_source\n",
    "\n",
    "        # Getting additional data of building\n",
    "        page_soup_new = soup(page_html_new, \"html.parser\")\n",
    "        data_container = page_soup_new.findAll(\"div\", {\"id\":\"reactGeneralFeatures\"})\n",
    "        if (len(data_container) > 0):\n",
    "            data_container = data_container[0]\n",
    "            info = data_container.findAll(\"li\")\n",
    "            if (info):\n",
    "                services = info[0].text.strip()\n",
    "                for i in range(1, len(info)):\n",
    "                    services = services + '-' + info[i].text.strip()\n",
    "            else:\n",
    "                services = \"None\"\n",
    "\n",
    "        # Getting building status\n",
    "        data_container = page_soup_new.findAll(\"div\", {\"class\":\"current\"})\n",
    "        if (len(data_container) > 0):\n",
    "            status = data_container[0].text.strip('\\n\\r\\tS/\",: ')\n",
    "        else:\n",
    "            status = \"None\"\n",
    "\n",
    "        # Getting delivery status\n",
    "        data_container = page_soup_new.findAll(\"div\", {\"class\":\"row\"})\n",
    "        if (len(data_container) > 0):    \n",
    "            delivery = data_container[0].text.strip('\\n\\r\\t\",: ').replace(\"\\n\\t\\t\\t\\t\\n\\n\", \" \")\n",
    "        else:\n",
    "            delivery = \"None\"\n",
    "\n",
    "        # Getting number of parking slots\n",
    "        if (parking_slots == \"None\"):\n",
    "            if (len(data_container)> 5):\n",
    "                parking_slots = data_container[5].text.strip('\\n\\r\\t\",: ').replace(\"\\n\\t\\t\\t\\t\\n\\n\", \" \")\n",
    "\n",
    "        # Getting date of publication\n",
    "\n",
    "        data_container = page_soup_new.findAll(\"span\", {\"class\":\"section-date\"})\n",
    "        if (len(data_container) > 0):\n",
    "            date_published= data_container[0].text.replace(\"Publicado hace\", \"\").strip('\\n\\r\\tS/\",: ')\n",
    "        else:\n",
    "            date_published = \"None\"\n",
    "\n",
    "        # Getting data of each apartment in the building\n",
    "\n",
    "        data_container = page_soup_new.findAll(\"div\", {\"class\": \"AccordionItem-td4pyq-0\"} )\n",
    "        if (len(data_container) > 0):\n",
    "            for i in range(len(data_container)):\n",
    "                bedrooms = data_container[i].findAll(\"h4\", {\"class\": \"AccordionTitle-td4pyq-2\"})[0].text\n",
    "                bedrooms = bedrooms[17:18]\n",
    "                new_data = data_container[i].findAll(\"div\", {\"class\": \"sc-bkzZxe\"})\n",
    "                for j in range(len(new_data)):\n",
    "                    price_text = new_data[j].findAll(\"div\", {\"class\": \"sc-idOhPF\" })\n",
    "                    area_text = new_data[j].findAll(\"li\")\n",
    "                    price = price_text[0].text.strip('\\n\\r\\tS/\",: ').replace(\",\", \"\")\n",
    "                    area = area_text[0].text\n",
    "                    if (len(area_text) > 1):\n",
    "                        bathrooms = area_text[1].text.strip('\\n\\r\\tS/\"bBaños,: ')\n",
    "                    else:\n",
    "                        bathrooms = \"None\"\n",
    "        \n",
    "            # Writing data for each apartment\n",
    "            f.write(address.replace(\",\", \"-\") + \",\" + price + \",\" + apartments + \",\" + bedrooms + \",\" + area + \",\" + \n",
    "                bathrooms + \",\" + parking_slots.replace(\"Estacionamientos \", \"\") + \",\" + status + \",\" + \n",
    "                delivery.replace(\"Entrega \", \"\") + \",\" + services + \",\" + date_published + \",\" + new_link + \"\\n\") \n",
    "                \n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
